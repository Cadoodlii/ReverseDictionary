{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c266a17",
   "metadata": {},
   "source": [
    "# Student model training & retrieval\n",
    "\n",
    "This notebook trains the `StudentModel` (text-only baseline) on `dataset.json`, implements a retrieval function that returns the closest words by cosine similarity given a definition, and computes recall@1/5/10 on a held-out test subset.\n",
    "\n",
    "Notes:\n",
    "- Make sure required packages are installed (`numpy`, `torch`, `transformers`, `tqdm`).\n",
    "- Run the cells sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5138c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catherineli/UMD/CMSC498K/Final Project/ReverseDictionary/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: torch, numpy, transformers\n"
     ]
    }
   ],
   "source": [
    "# Check environment and show install suggestions\n",
    "try:\n",
    "    import torch, numpy as np\n",
    "    import transformers\n",
    "    print('Found: torch, numpy, transformers')\n",
    "except Exception as e:\n",
    "    print('Missing packages. Install with:')\n",
    "    print('  python3 -m pip install numpy torch transformers tqdm')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44b63d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "# Imports and helpers\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from student import (\n",
    "    load_glove_embeddings,\n",
    "    TextOnlyDataset,\n",
    "    StudentModel,\n",
    "    collate_examples,\n",
    "    train_one_epoch,\n",
    "    evaluate,\n",
    ")\n",
    "\n",
    "print('Imports OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a39ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "DATASET = 'dataset.json'\n",
    "GLOVE = './glove.6B.300d.txt'\n",
    "BERT = 'bert-base-uncased'\n",
    "BATCH = 16\n",
    "EPOCHS = 20\n",
    "LR = 2e-5\n",
    "MAXLEN = 128\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print('Device:', DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1332729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe...\n",
      "GloVe dim = 300\n",
      "Loading dataset...\n",
      "GloVe dim = 300\n",
      "Loading dataset...\n",
      "Dataset size: 971\n",
      "Train size: 873 Test size: 98\n",
      "Dataset size: 971\n",
      "Train size: 873 Test size: 98\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe and dataset\n",
    "print('Loading GloVe...')\n",
    "glove = load_glove_embeddings(GLOVE)\n",
    "print('GloVe dim =', next(iter(glove.values())).shape[0])\n",
    "\n",
    "print('Loading dataset...')\n",
    "ds = TextOnlyDataset(DATASET, glove, tokenizer_name=BERT, max_length=MAXLEN)\n",
    "\n",
    "n = len(ds)\n",
    "print('Dataset size:', n)\n",
    "\n",
    "# 90/10 split for train/test\n",
    "train_n = int(0.9 * n)\n",
    "indices = list(range(n))\n",
    "train_idx = indices[:train_n]\n",
    "test_idx = indices[train_n:]\n",
    "\n",
    "train_ds = torch.utils.data.Subset(ds, train_idx)\n",
    "test_ds = torch.utils.data.Subset(ds, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, collate_fn=lambda x: collate_examples(x))\n",
    "val_loader = DataLoader(test_ds, batch_size=BATCH, shuffle=False, collate_fn=lambda x: collate_examples(x))\n",
    "\n",
    "print('Train size:', len(train_ds), 'Test size:', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933f52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created; training will run for 20 epochs\n"
     ]
    }
   ],
   "source": [
    "# Build model, optimizer, criterion\n",
    "model = StudentModel(bert_model_name=BERT, target_dim=next(iter(glove.values())).shape[0])\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=LR)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "print('Model created; training will run for', EPOCHS, 'epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae377d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.145486 val_loss=0.136229\n",
      "Epoch 2: train_loss=0.125500 val_loss=0.132963\n",
      "Epoch 2: train_loss=0.125500 val_loss=0.132963\n",
      "Epoch 3: train_loss=0.123059 val_loss=0.133009\n",
      "Epoch 3: train_loss=0.123059 val_loss=0.133009\n",
      "Epoch 4: train_loss=0.121099 val_loss=0.132300\n",
      "Epoch 4: train_loss=0.121099 val_loss=0.132300\n",
      "Epoch 5: train_loss=0.118541 val_loss=0.131882\n",
      "Epoch 5: train_loss=0.118541 val_loss=0.131882\n",
      "Epoch 6: train_loss=0.116033 val_loss=0.131826\n",
      "Epoch 6: train_loss=0.116033 val_loss=0.131826\n",
      "Epoch 7: train_loss=0.113363 val_loss=0.130568\n",
      "Epoch 7: train_loss=0.113363 val_loss=0.130568\n",
      "Epoch 8: train_loss=0.110353 val_loss=0.129420\n",
      "Epoch 8: train_loss=0.110353 val_loss=0.129420\n",
      "Epoch 9: train_loss=0.107267 val_loss=0.128645\n",
      "Epoch 9: train_loss=0.107267 val_loss=0.128645\n",
      "Epoch 10: train_loss=0.103967 val_loss=0.128849\n",
      "Epoch 10: train_loss=0.103967 val_loss=0.128849\n",
      "Epoch 11: train_loss=0.100713 val_loss=0.129115\n",
      "Epoch 11: train_loss=0.100713 val_loss=0.129115\n",
      "Epoch 12: train_loss=0.097131 val_loss=0.130102\n",
      "Epoch 12: train_loss=0.097131 val_loss=0.130102\n",
      "Epoch 13: train_loss=0.094475 val_loss=0.127146\n",
      "Epoch 13: train_loss=0.094475 val_loss=0.127146\n",
      "Epoch 14: train_loss=0.091771 val_loss=0.127546\n",
      "Epoch 14: train_loss=0.091771 val_loss=0.127546\n",
      "Epoch 15: train_loss=0.089424 val_loss=0.128449\n",
      "Epoch 15: train_loss=0.089424 val_loss=0.128449\n",
      "Epoch 16: train_loss=0.086979 val_loss=0.128405\n",
      "Epoch 16: train_loss=0.086979 val_loss=0.128405\n",
      "Epoch 17: train_loss=0.084640 val_loss=0.127843\n",
      "Epoch 17: train_loss=0.084640 val_loss=0.127843\n",
      "Epoch 18: train_loss=0.082677 val_loss=0.129653\n",
      "Epoch 18: train_loss=0.082677 val_loss=0.129653\n",
      "Epoch 19: train_loss=0.080687 val_loss=0.128095\n",
      "Epoch 19: train_loss=0.080687 val_loss=0.128095\n",
      "Epoch 20: train_loss=0.078635 val_loss=0.128145\n",
      "Epoch 20: train_loss=0.078635 val_loss=0.128145\n",
      "Saved model to ckpts/student_model.pt\n",
      "Saved model to ckpts/student_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, DEVICE, criterion)\n",
    "    val_loss = evaluate(model, val_loader, DEVICE, criterion)\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.6f} val_loss={val_loss:.6f}\")\n",
    "\n",
    "# Optionally save the model\n",
    "model_path = Path('./ckpts/student_model.pt')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Saved model to', model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8ed554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval helper ready\n"
     ]
    }
   ],
   "source": [
    "# Prepare database vectors and retrieval helpers\n",
    "# db_words / db_vectors cover the entire dataset (used for retrieval)\n",
    "db_words = [ex['word'] for ex in ds.examples]\n",
    "db_vectors = np.stack([ex['vector'] for ex in ds.examples])  # shape (N, D)\n",
    "\n",
    "# normalize db vectors (L2)\n",
    "db_norms = np.linalg.norm(db_vectors, axis=1)\n",
    "# avoid division by zero\n",
    "db_norms[db_norms == 0] = 1.0\n",
    "\n",
    "\n",
    "def retrieve_topk(definition, k=10, model=model, tokenizer=ds.tokenizer, maxlen=MAXLEN, device=DEVICE):\n",
    "    # encode definition\n",
    "    toks = tokenizer(definition, truncation=True, padding='max_length', max_length=maxlen, return_tensors='pt')\n",
    "    input_ids = toks['input_ids'].to(device)\n",
    "    attention_mask = toks['attention_mask'].to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        q = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    q = q.cpu().numpy().reshape(-1)  # (D,)\n",
    "    q_norm = np.linalg.norm(q)\n",
    "    if q_norm == 0:\n",
    "        q_norm = 1.0\n",
    "    sims = (db_vectors @ q) / (db_norms * q_norm)\n",
    "    idxs = np.argsort(-sims)[:k]\n",
    "    return [(db_words[i], float(sims[i])) for i in idxs]\n",
    "\n",
    "print('Retrieval helper ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95f2586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating recall: 100%|██████████| 98/98 [00:01<00:00, 56.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num test examples: 98\n",
      "Recall@1: 6/98 = 0.0612\n",
      "Recall@5: 15/98 = 0.1531\n",
      "Recall@10: 26/98 = 0.2653\n",
      "Recall@20: 36/98 = 0.3673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute recall@1,5,10 on the held-out test set\n",
    "from collections import defaultdict\n",
    "k_values = [1,5,10, 20]\n",
    "correct = defaultdict(int)\n",
    "\n",
    "for idx in tqdm(test_idx, desc='Evaluating recall'):\n",
    "    ex = ds.examples[idx]\n",
    "    gt_word = ex['word']\n",
    "    topk = retrieve_topk(ex['definition'], k=max(k_values))\n",
    "    retrieved = [w for w,_ in topk]\n",
    "    for k in k_values:\n",
    "        if gt_word in retrieved[:k]:\n",
    "            correct[k] += 1\n",
    "\n",
    "num_test = len(test_idx)\n",
    "print('Num test examples:', num_test)\n",
    "for k in k_values:\n",
    "    print(f'Recall@{k}: {correct[k]}/{num_test} = {correct[k]/num_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e0431",
   "metadata": {},
   "source": [
    "Demo retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65dc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from student import load_glove_embeddings, TextOnlyDataset, StudentModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "GLOVE = './glove.6B.300d.txt'\n",
    "DATASET = 'dataset.json'\n",
    "MODEL_PATH = './ckpts/student_model.pt'\n",
    "\n",
    "print('Loading GloVe...')\n",
    "glove = load_glove_embeddings(GLOVE)\n",
    "dim = next(iter(glove.values())).shape[0]\n",
    "print('GloVe dim:', dim)\n",
    "\n",
    "print('Loading dataset...')\n",
    "ds = TextOnlyDataset(DATASET, glove, tokenizer_name='bert-base-uncased', max_length=128)\n",
    "print('Dataset examples:', len(ds))\n",
    "\n",
    "# build model\n",
    "# model = StudentModel(bert_model_name='bert-base-uncased', target_dim=dim)\n",
    "# prefer CPU for reproducibility here\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# try load weights if available\n",
    "if Path(MODEL_PATH).exists():\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "        print('Loaded model weights from', MODEL_PATH)\n",
    "    except Exception as e:\n",
    "        print('Failed to load model weights:', e)\n",
    "else:\n",
    "    print('No model weights found at', MODEL_PATH, '- using randomly initialized model')\n",
    "\n",
    "# prepare DB vectors and mapping\n",
    "db_words = [ex['word'] for ex in ds.examples]\n",
    "db_defs = [ex['definition'] for ex in ds.examples]\n",
    "db_vectors = np.stack([ex['vector'] for ex in ds.examples])\n",
    "# normalize\n",
    "db_norms = np.linalg.norm(db_vectors, axis=1)\n",
    "db_norms[db_norms==0] = 1.0\n",
    "\n",
    "# retrieval function\n",
    "from student import TextOnlyDataset\n",
    "\n",
    "def retrieve_topk(definition, k=5):\n",
    "    tokenizer = ds.tokenizer\n",
    "    toks = tokenizer(definition, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
    "    input_ids = toks['input_ids'].to(device)\n",
    "    attention_mask = toks['attention_mask'].to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        q = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    q = q.cpu().numpy().reshape(-1)\n",
    "    q_norm = np.linalg.norm(q)\n",
    "    if q_norm == 0:\n",
    "        q_norm = 1.0\n",
    "    sims = (db_vectors @ q) / (db_norms * q_norm)\n",
    "    idxs = np.argsort(-sims)[:k]\n",
    "    return [(db_words[i], db_defs[i], float(sims[i])) for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(idx):\n",
    "    # pick a random definition\n",
    "    query_def = ds.examples[idx]['definition']\n",
    "    query_word = ds.examples[idx]['word']\n",
    "    print('\\nRandom query definition (from dataset index {}):\\n\"{}\"\\n'.format(rand_idx, query_def))\n",
    "    print('Query word is \"{}\"\\n'.format(query_word))\n",
    "\n",
    "    # run retrieval\n",
    "    topk = retrieve_topk(query_def, k=10)\n",
    "    print('Top-10 retrieved:')\n",
    "    for i,(w,d,s) in enumerate(topk,1):\n",
    "        print(f\"{i}. {w} (sim={s:.4f}) -- definition: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3dd1f05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random query definition (from dataset index 503):\n",
      "\"a rugged box (usually made of wood); used for shipping\"\n",
      "\n",
      "Query word is \"crate\"\n",
      "\n",
      "Top-10 retrieved:\n",
      "1. crate (sim=0.6892) -- definition: a rugged box (usually made of wood); used for shipping\n",
      "2. plastic_bag (sim=0.4852) -- definition: a bag made of thin plastic material\n",
      "3. refrigerator (sim=0.4830) -- definition: white goods in which food can be stored at low temperatures\n",
      "4. bucket (sim=0.4784) -- definition: a roughly cylindrical vessel that is open at the top\n",
      "5. punching_bag (sim=0.4559) -- definition: an inflated ball or bag that is suspended and punched for training in boxing\n",
      "6. carton (sim=0.4515) -- definition: a box made of cardboard; opens by flaps on top\n",
      "7. sleeping_bag (sim=0.4310) -- definition: large padded bag designed to be slept in outdoors; usually rolls up like a bedroll\n",
      "8. shovel (sim=0.4239) -- definition: a hand tool for lifting loose material; consists of a curved container or scoop and a handle\n",
      "9. wooden_spoon (sim=0.4141) -- definition: a spoon made of wood\n",
      "10. tray (sim=0.4114) -- definition: an open receptacle for holding or displaying or serving articles or food\n"
     ]
    }
   ],
   "source": [
    "# pick a random definition\n",
    "rand_idx = random.randrange(len(ds.examples))\n",
    "demo(rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb05c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random query definition (from dataset index 907):\n",
      "\"potato that has been peeled and boiled and then mashed\"\n",
      "\n",
      "Query word is \"mashed_potato\"\n",
      "\n",
      "Top-10 retrieved:\n",
      "1. zucchini (sim=0.4902) -- definition: small cucumber-shaped vegetable marrow; typically dark green\n",
      "2. Crock_Pot (sim=0.4830) -- definition: an electric cooker that maintains a relatively low temperature\n",
      "3. mashed_potato (sim=0.4733) -- definition: potato that has been peeled and boiled and then mashed\n",
      "4. cauliflower (sim=0.4615) -- definition: compact head of white undeveloped flowers\n",
      "5. ladle (sim=0.4563) -- definition: a spoon-shaped vessel with a long handle; frequently used to transfer liquids from one container to another\n",
      "6. wok (sim=0.4535) -- definition: pan with a convex bottom; used for frying in Chinese cooking\n",
      "7. cucumber (sim=0.4480) -- definition: cylindrical green fruit with thin green rind and white flesh eaten as a vegetable; related to melons\n",
      "8. stove (sim=0.4414) -- definition: any heating apparatus\n",
      "9. Petri_dish (sim=0.4392) -- definition: a shallow dish used to culture bacteria\n",
      "10. chocolate_sauce (sim=0.4332) -- definition: sauce made with unsweetened chocolate or cocoa and sugar and water\n"
     ]
    }
   ],
   "source": [
    "# pick a random definition\n",
    "rand_idx = random.randrange(len(ds.examples))\n",
    "demo(rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39c1b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random query definition (from dataset index 174):\n",
      "\"English breed of strong stocky dog having a broad skull and smooth coat\"\n",
      "\n",
      "Query word is \"Staffordshire_bullterrier\"\n",
      "\n",
      "Top-10 retrieved:\n",
      "1. Yorkshire_terrier (sim=0.7629) -- definition: very small breed having a long glossy coat of bluish-grey and tan\n",
      "2. American_Staffordshire_terrier (sim=0.7381) -- definition: American breed of muscular terriers with a short close-lying stiff coat\n",
      "3. Norwich_terrier (sim=0.7319) -- definition: English breed of small short-legged terrier with a straight wiry red or grey or black-and-tan coat and erect ears\n",
      "4. Irish_terrier (sim=0.7316) -- definition: medium-sized breed with a wiry brown coat; developed in Ireland\n",
      "5. Norfolk_terrier (sim=0.7284) -- definition: English breed of small terrier with a straight wiry grizzled coat and dropped ears\n",
      "6. Scotch_terrier (sim=0.6965) -- definition: old Scottish breed of small long-haired usually black terrier with erect tail and ears\n",
      "7. soft-coated_wheaten_terrier (sim=0.6919) -- definition: Irish breed of medium-sized terrier with an abundant coat any shade of wheat and very hairy head and muzzle\n",
      "8. Sealyham_terrier (sim=0.6845) -- definition: a wire-haired terrier with short legs that was first bred in Sealyham\n",
      "9. Bedlington_terrier (sim=0.6699) -- definition: a light terrier groomed to resemble a lamb\n",
      "10. silky_terrier (sim=0.6525) -- definition: Australian breed of toy dogs having a silky blue coat\n"
     ]
    }
   ],
   "source": [
    "# pick a random definition\n",
    "rand_idx = random.randrange(len(ds.examples))\n",
    "demo(rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0898da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random query definition (from dataset index 850):\n",
      "\"a keyboard for manually entering characters to be printed\"\n",
      "\n",
      "Query word is \"typewriter_keyboard\"\n",
      "\n",
      "Top-10 retrieved:\n",
      "1. typewriter_keyboard (sim=0.8040) -- definition: a keyboard for manually entering characters to be printed\n",
      "2. computer_keyboard (sim=0.7213) -- definition: a keyboard that is a data input device for computers; arrangement of keys is modelled after the typewriter keyboard\n",
      "3. accordion (sim=0.5960) -- definition: a portable box-shaped free-reed instrument; the reeds are made to vibrate by air from the bellows controlled by the player\n",
      "4. acoustic_guitar (sim=0.5802) -- definition: sound is not amplified by electrical means\n",
      "5. cello (sim=0.5788) -- definition: a large stringed instrument; seated player holds it upright while playing\n",
      "6. violin (sim=0.5751) -- definition: bowed stringed instrument that is the highest member of the violin family; this instrument has four strings and a hollow body and an unfretted fingerboard and is played with a bow\n",
      "7. electric_guitar (sim=0.5592) -- definition: a guitar whose sound is amplified by electrical means\n",
      "8. harmonica (sim=0.5361) -- definition: a small rectangular free-reed instrument having a row of free reeds set back in air holes and played by blowing into the desired hole\n",
      "9. hand-held_computer (sim=0.5342) -- definition: a portable battery-powered computer small enough to be carried in your pocket\n",
      "10. cassette_player (sim=0.5238) -- definition: electronic equipment for playing cassettes\n"
     ]
    }
   ],
   "source": [
    "# pick a random definition\n",
    "rand_idx = random.randrange(len(ds.examples))\n",
    "demo(rand_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
